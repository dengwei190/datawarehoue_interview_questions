### 1. Hive与关系型数据库的区别

* 除了语句类似，其余都不同
* Hive是逻辑上的数据仓库，实际操作的都是HDFS上的文件，不能像数据库一样进行实时的CURD操作。是一次写入，多次读取的操作，可以看成是ETL工具
* Hive中不能删除/修改数据，不建议插入更新数据
* Hive底层是Mapreduce 程序，所以执行延时比较高
* Hive处理的是大数据规模的，mysql要小很多
* Hive用于大数据场景的计算，用于OLAP分析性业务；Mysql一般用于业务型 OLTP

### 2. Hive元数据管理的几种方式

* 内嵌模式*（默认，但一般不用）*：内嵌数据库derby，安装小，基于Java、JDBC和SQL标准
* 本地模式*（一般采用）*：MySql数据库数据存储模式可以自己设置，持久化好，查看方便
* 远程模式：用于非Java客户端访问元数据库，在服务器端启动MetaStoreServer，客户端利用Thrift协议通过MetaStoreServer访问元数据库

### 3. 四种排序方式

* order by ：会对输入做全局排序，因此只有一个reducer*（多个reducer无法保证全局有序）*，当输入规模较大时，需要较长的计算时间
* sort by ：分区排序，只能保证在同一个reduce中的数据可以按指定字段排序，需设置mapred.reduce.tasks>1

* distribute by：控制在map端如何拆分数据给reduce端的，默认采用hash算法，类似于SQL中的 group by 
* cluster by：当distribute by 和 sort by 的字段相同时等同于cluster by 

### 4. 内部表和外部表的区别

* 外部表：建表时使用external关键字，Hive不完全管理数据，删除表（元数据）不会删除数据
* 内部表：数据完全由Hive管理，输出表（元数据）时会删除数据
* 为什么建议使用外部表：
  * 不需要再将数据重新创建一便
  * 加载外部表时，不会对原始数据的内容进行修改，保证数据还是原来的数据

### 5. 静态分区和动态分区

​		静态分区与动态分区的主要区别在于静态分区是手动指定的，而动态分区是通过数据来进行判断；要使用动态分区则需要开启几个参数

### 6. 自定义UDF（自定义函数）的步骤

​		继承UDF类或GenericUDF类—》重写evaluate()方法并实现函数逻辑—》编译打包为jar文件—》复制到正确的HDFS路径—》使用jar创建临时/永久函数—》调用函数

* 处理哪些业务？
  * 在项目里，对采集过来的日志数据的解析；归一化处理、求位置相似度

### 7. 窗口函数

​	**Function (arg1,...,** **arg** **n) OVER ([PARTITION BY <...>] [ORDER BY <....>] [])**

* 序列：ROW_NUMBER()—>(1,2,3)、RANK()—>(1,1,3)、DENSE_RANK()—>(1,1,2)

* 聚合：COUNT()、SUN()、AVG()、MAX()/MIN()

* 分析：CUME_DIST：小于等于当前值的行数；LEAD/LAG(col,n)：某一列进行往前/后第n行的值；FIRST_VALUE/LAST_VALUE：该列目前为止的首个/最后一个值

### 8. Hive底层如何转换成MR的

​		在Driver端进行

* 解析器：将SQL字符串转换成抽象语法树AST（可用explain查看）
* 编译器：将抽象语法树AST生产逻辑执行计划
* 优化器：对逻辑执行计划进行优化
* 执行器：将逻辑执行计划转换成可以运行的物理计划

### 9. Hive做过哪些优化

* 采用分区/分桶技术、设置本地模式、并行执行、JVM重用、严格模式、Fetch抓取、合理的map个数和reduce个数、处理小文件（控制切片个数/小文件合并）、多用临时表（避免中间数据多次计算）
* 数据存储及压缩：Hive中表的存储格式通常有orc和parquet，压缩格式一般使用snappy。相比textfile格式表，orc占有更少的存储。因为hive底层使用MR计算架构，数据流是hdfs到磁盘再到hdfs，而且会有很多次，所以使用orc数据格式和snappy压缩策略可以降低IO读写，还能降低网络传输量，这样在一定程度上可以节省存储，还能提升hql任务执行效率

* 通过调参优化：
  * 并行执行，调节parallel参数；
  * 调节jvm参数，重用jvm；
  * 设置合适的map、reduce的参数
  * 开启strict mode模式
  * 关闭推测执行设置

* 有效的减小数据集
  * 将大表拆分成子表
  * 结合使用外部表和分区表

* SQL优化
  * 大表对大表：尽量减少数据集，通过使用分区表，避免扫描全表或者全字段
  * 大表对小表：设置自动识别小表，将小表放入内存中去执行

### 10. Hive数据倾斜

#### 10.1 产生原因

* key分布不均匀
* 业务数据本身的特性
* 建表时考虑不周
* 某些SQL语句本身就有倾斜
  * 大表join小表，其中小表key集中，分发到某一个或几个Reduce上的数据远高于平均值
  * 大表join大表，但是分桶的判断字段0值或空值过多，这些空值都由一个reduce处理，非常慢
  * group by 的维度过小，某值的数量过多，处理某值的reduce非常耗时
  * Count Distinct，某特殊值过多，处理此特殊值的reduce耗时

#### 10.2 解决方案

* 参数调节：hive.map.aggr=true              hive.groupby.skewindata=true

* SQL调整：
  * 选用join key分布最均匀的表作为驱动表。做好列裁剪和filter操作，以达到两表join的时候，数据量相对变小的情况
  * 大小表join：使用map join让小的维度表（1000条以下的记录条数）先进内存。在Map端完成Reduce
  * 大表join大表：把空值的key变成一个字符串加上一个随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后并不影响最终结果
  * group by 维度过小：采用sum() group by的方式来替换count(distinct)完成计算。
  * count distinct大量相同特殊值，将值为空的情况单独处理，如果是计算count distinct，可以不用处理，直接过滤，在最后结果中加1。如果还需要计算，需要进行group by ，可以先将值为空的记录单独处理，再和其他计算结果进行union

* 合理的map个数和reduce个数
* 采用分区/分桶表

### 11. 历史数据如何变更

拉链表：

* 所谓拉链，就是记录历史。记录一个事物从开始，一直到当前状态的所有变化的信息
* 拉链表存储的是用户的最基本信息以及每条记录的生命周期：缓慢变更维度
* 可以使用这张表拿到最新的当天的最新数据以及之前的历史数据